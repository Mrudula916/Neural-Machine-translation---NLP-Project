{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":880,"status":"ok","timestamp":1660429742870,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"},"user_tz":240},"id":"4IIDky3DWV4F","outputId":"81665bb4-dff6-471c-e1a7-e56942f206c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Tkm-d_szQwKg","executionInfo":{"status":"ok","timestamp":1660429746121,"user_tz":240,"elapsed":3254,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import string\n","from string import digits\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import tensorflow as tf\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","import re\n","import os\n","import io\n","import time"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":923,"status":"ok","timestamp":1660429747039,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"},"user_tz":240},"id":"P0qXnkiEQyu1","outputId":"106c1eb8-0d2c-4251-b571-e3d46a87982f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          source  \\\n","104996    They're in trouble. Can you help them?   \n","19482                        Everyone's waiting.   \n","109584  Illness prevented me from taking a trip.   \n","15499                         Can we see it now?   \n","5691                              It was ironic.   \n","\n","                                               target  \\\n","104996  Ellas están en problemas. ¿Las puedes ayudar?   \n","19482                          Todos están esperando.   \n","109584      La enfermedad me impidió el dar un viaje.   \n","15499                           ¿Podemos verlo ahora?   \n","5691                                     Fue irónico.   \n","\n","                                                 comments  \n","104996  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n","19482   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","109584  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n","15499   CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n","5691    CC-BY 2.0 (France) Attribution: tatoeba.org #1...  "],"text/html":["\n","  <div id=\"df-2f5b3545-a04c-437e-8b5a-e9d8cde4f5c0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>104996</th>\n","      <td>They're in trouble. Can you help them?</td>\n","      <td>Ellas están en problemas. ¿Las puedes ayudar?</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>19482</th>\n","      <td>Everyone's waiting.</td>\n","      <td>Todos están esperando.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>109584</th>\n","      <td>Illness prevented me from taking a trip.</td>\n","      <td>La enfermedad me impidió el dar un viaje.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n","    </tr>\n","    <tr>\n","      <th>15499</th>\n","      <td>Can we see it now?</td>\n","      <td>¿Podemos verlo ahora?</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n","    </tr>\n","    <tr>\n","      <th>5691</th>\n","      <td>It was ironic.</td>\n","      <td>Fue irónico.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f5b3545-a04c-437e-8b5a-e9d8cde4f5c0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f5b3545-a04c-437e-8b5a-e9d8cde4f5c0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f5b3545-a04c-437e-8b5a-e9d8cde4f5c0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["data_path = \"/content/drive/MyDrive/Neural Machine Translation/Dataset/spa.txt\"\n","#Read the data\n","lines_raw= pd.read_table(data_path,names=['source', 'target', 'comments'])\n","lines_raw.sample(5)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Si7c4nDKRvet","executionInfo":{"status":"ok","timestamp":1660429747040,"user_tz":240,"elapsed":6,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["def preprocess_sentence(sentence):\n","    \n","    num_digits= str.maketrans('','', digits)\n","    \n","    sentence= sentence.lower()\n","    sentence= re.sub(\" +\", \" \", sentence)\n","    sentence= re.sub(\"'\", '', sentence)\n","    sentence= sentence.translate(num_digits)\n","    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n","    sentence = sentence.rstrip().strip()\n","    sentence=  'start_ ' + sentence + ' _end'\n","    \n","    return sentence"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A0BTvMYlRzEw","executionInfo":{"status":"ok","timestamp":1660429749337,"user_tz":240,"elapsed":2302,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["def create_dataset(path, num_examples):\n","  \n","  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","  \n","  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n","  \n","  return zip(*word_pairs)\n","\n","\n","sample_size=60000\n","target, source, comments = create_dataset(data_path, sample_size)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1MIDBK0rRkMKSa7_MRiP2CGCZXmVhH4gI"},"executionInfo":{"elapsed":1395,"status":"ok","timestamp":1660429750727,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"},"user_tz":240},"id":"lzRfeO-2Uq8u","outputId":"550975bf-f9d3-4d5c-f908-751ac33080e3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["print(source)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"A42FPDZkRz16","executionInfo":{"status":"ok","timestamp":1660429750876,"user_tz":240,"elapsed":151,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["# create a tokenizer for source sentence\n","source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n","# Fit the source sentences to the source tokenizer\n","source_sentence_tokenizer.fit_on_texts(source)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ae9xs8jWR2cQ","executionInfo":{"status":"ok","timestamp":1660429750877,"user_tz":240,"elapsed":3,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["#Transforms each text in texts to a sequence of integers.\n","source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"EKqDuVzlR5aS","executionInfo":{"status":"ok","timestamp":1660429751451,"user_tz":240,"elapsed":576,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["#Sequences that are shorter than num_timesteps, padded with 0 at the end.\n","source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"1Gui_P9BR9A0","executionInfo":{"status":"ok","timestamp":1660429751960,"user_tz":240,"elapsed":511,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["# create the target sentence tokenizer\n","target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n","# Fit the tokenizer on target sentences\n","target_sentence_tokenizer.fit_on_texts(target)\n","#conver target text to sequnec of integers\n","target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n","# Post pad the shorter sequences with 0\n","target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"-HAPE2h3R_WT","executionInfo":{"status":"ok","timestamp":1660429751960,"user_tz":240,"elapsed":6,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.1)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"D-b11OjySGyf","executionInfo":{"status":"ok","timestamp":1660429755295,"user_tz":240,"elapsed":3198,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["#setting the BATCH SIZE\n","BATCH_SIZE = 64\n","#Create data in memeory \n","dataset=tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BATCH_SIZE)\n","# shuffles the data in the batch\n","dataset = dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1660429755295,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"},"user_tz":240},"id":"s1T3nttfSLlY","outputId":"59e255cb-cf9e-4d28-e4fd-f0643fe280b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 16)\n"]}],"source":["#Creates an Iterator for enumerating the elements of this dataset.\n","#Extract the next element from the dataset\n","source_batch, target_batch =next(iter(dataset))\n","print(source_batch.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"REDNFz4WSVen","executionInfo":{"status":"ok","timestamp":1660429755296,"user_tz":240,"elapsed":5,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["BUFFER_SIZE = len(source_train_tensor)\n","steps_per_epoch= len(source_train_tensor)//BATCH_SIZE\n","embedding_dim=256\n","units=1024\n","source_vocab_size= len(source_sentence_tokenizer.word_index)+1\n","target_vocab_size= len(target_sentence_tokenizer.word_index)+1"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"CEcKqSccSZ7e","executionInfo":{"status":"ok","timestamp":1660429755296,"user_tz":240,"elapsed":4,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences = False,\n","                                   return_state= True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    state = self.gru(x, initial_state = hidden)\n","    return state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2549,"status":"ok","timestamp":1660429757841,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"},"user_tz":240},"id":"FJovauI4Scze","outputId":"5bf85f50-9180-429f-ec7d-8766f53dfd66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder output shape: (batch size, sequence length, units) (64, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"]}],"source":["encoder = Encoder(source_vocab_size, embedding_dim, units, BATCH_SIZE)\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden= encoder(source_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"KQiHEaGdSmd1","executionInfo":{"status":"ok","timestamp":1660429757841,"user_tz":240,"elapsed":6,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences = False,\n","                                   return_state= True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    # self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    # context_vector, attention_weights = encoder(enc_output, [hidden])\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(hidden, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[1]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, output"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1978,"status":"ok","timestamp":1660429759815,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"},"user_tz":240},"id":"MrbUrKfSSyYu","outputId":"63a0bc14-9350-47cc-eafe-67f88e623ecf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder output shape: (batch_size, vocab size) (64, 7601)\n"]}],"source":["decoder= Decoder(target_vocab_size, embedding_dim, units, BATCH_SIZE)\n","sample_decoder_output, _ = decoder(tf.random.uniform((BATCH_SIZE,1)), sample_hidden, sample_output)\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"PqK5oIdHS8Du","executionInfo":{"status":"ok","timestamp":1660429759816,"user_tz":240,"elapsed":13,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["#Define the optimizer and the loss function\n","optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"BREYdRp3TH4x","executionInfo":{"status":"ok","timestamp":1660429759816,"user_tz":240,"elapsed":11,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ShjpyXw_TKPS","executionInfo":{"status":"ok","timestamp":1660429759817,"user_tz":240,"elapsed":11,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["def train_step(inp, targ, enc_hidden):\n","    loss = 0\n","    with tf.GradientTape() as tape:\n","        #create encoder\n","        enc_output= encoder(inp, enc_hidden)\n","        dec_hidden = enc_hidden\n","        #first input to decode is start_\n","        dec_input = tf.expand_dims(\n","            [target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n","        # Teacher forcing - feeding the target as the next input\n","        for t in range(1, targ.shape[1]):\n","          # passing enc_output to the decoder\n","          predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n","          # calculate loss based on predictions  \n","          loss += tf.keras.losses.sparse_categorical_crossentropy(targ[:, t], predictions)\n","          # using teacher forcing\n","          dec_input = tf.expand_dims(targ[:, t], 1)\n","    batch_loss = (loss / int(targ.shape[1]))\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","    # gradients = tape.gradient(loss, variables)\n","    # optimizer.apply_gradients(zip(gradients, variables))\n","    return batch_loss"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"JyJ60fvnTOsD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660430025289,"user_tz":240,"elapsed":158,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}},"outputId":"19c54419-2ebb-4774-9840-57941e0c77b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1 --> Train loss: 10.545, Val loss: 10.384, Epoch time : 490s\n","Epoch: 2 --> Train loss: 10.345, Val loss: 10.456, Epoch time : 478s\n","Epoch: 3 -->  Train loss: 10.220, Val loss: 10.471, Epoch time : 488s\n","Epoch: 4 -->  Train loss: 10.209, Val loss: 10.312, Epoch time : 468s\n","Epoch: 5 -->  Train loss: 10.170, Val loss: 10.158, Epoch time : 457s\n","Epoch: 6 -->  Train loss: 10.128, Val loss: 10.109, Epoch time : 503s\n","Epoch: 7 -->  Train loss: 10.105, Val loss: 10.231, Epoch time : 496s\n","Epoch: 8 -->  Train loss: 10.008, Val loss: 10.187, Epoch time : 467s\n","Epoch: 9 -->  Train loss: 9.987, Val loss: 10.001, Epoch time : 502s\n","Epoch: 10 -->  Train loss: 9.450, Val loss: 9.399, Epoch time : 490s\n","Epoch: 11 -->  Train loss: 9.298, Val loss: 9.208, Epoch time : 493s\n","Epoch: 12 -->  Train loss: 9.243, Val loss: 9.112, Epoch time : 467s\n","Epoch: 13 -->  Train loss: 8.732, Val loss: 9.004, Epoch time : 489s\n","Epoch: 14 -->  Train loss: 8.519, Val loss: 8.452, Epoch time : 495s\n","Epoch: 15 -->  Train loss: 7.570, Val loss: 7.498, Epoch time : 488s\n","Epoch: 16 -->  Train loss: 7.127, Val loss: 7.119, Epoch time : 438s\n","Epoch: 17 -->  Train loss: 6.817, Val loss: 6.979, Epoch time : 519s\n","Epoch: 18 -->  Train loss: 6.198, Val loss: 6.298, Epoch time : 456s\n","Epoch: 19 -->  Train loss: 5.735, Val loss: 5.876, Epoch time : 487s\n","Epoch: 20 -->  Train loss: 5.009, Val loss: 5.898, Epoch time : 493s\n","Epoch: 21 -->  Train loss: 4.627, Val loss: 4.754, Epoch time : 467s\n","Epoch: 22 -->  Train loss: 4.301, Val loss: 4.446, Epoch time : 410s\n","Epoch: 23 -->  Train loss: 4.108, Val loss: 4.239, Epoch time : 498s\n","Epoch: 24 -->  Train loss: 3.957, Val loss: 4.114, Epoch time : 501s\n","Epoch: 25 -->  Train loss: 3.109, Val loss: 3.899, Epoch time : 460s\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n","import tensorflow as tf\n","EPOCHS = 20\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","  # train the model using data in bataches \n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","  if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {}'.format(epoch + 1,\n","                                                   batch,                                                   \n","                                         batch_loss.numpy()))\n","  print('Epoch {} Loss {}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"gcNlyqhUTSMi","executionInfo":{"status":"ok","timestamp":1660430037992,"user_tz":240,"elapsed":130,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["#Calculating the max length of the source and target sentences\n","max_target_length= max(len(t) for t in  target_tensor)\n","max_source_length= max(len(t) for t in source_tensor)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"-WPphxlqTUZS","executionInfo":{"status":"ok","timestamp":1660430038116,"user_tz":240,"elapsed":5,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["def evaluate(sentence):\n","    attention_plot= np.zeros((max_target_length, max_source_length))\n","    #preprocess the sentnece\n","    sentence = preprocess_sentence(sentence)\n","    \n","    #convert the sentence to index based on word2index dictionary\n","    inputs= [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n","    \n","    # pad the sequence \n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_source_length, padding='post')\n","    \n","    #conver to tensors\n","    inputs = tf.convert_to_tensor(inputs)\n","    \n","    result= ''\n","    \n","    # creating encoder\n","    hidden = [tf.zeros((1, units))]\n","    encoder_output, encoder_hidden= encoder(inputs, hidden)\n","    \n","    # creating decoder\n","    decoder_hidden = encoder_hidden\n","    decoder_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n","    \n","    for t in range(max_target_length):\n","        predictions, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n","        \n","        prediction_id= tf.argmax(predictions[0]).numpy()\n","        result += target_sentence_tokenizer.index_word[prediction_id] + ' '\n","        \n","        if target_sentence_tokenizer.index_word[prediction_id] == '_end':\n","            return result,sentence, attention_plot\n","        \n","        # predicted id is fed back to as input to the decoder\n","        decoder_input = tf.expand_dims([prediction_id], 0)\n","        \n","    return result,sentence"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"MUDnFpQwTgSj","executionInfo":{"status":"ok","timestamp":1660430038117,"user_tz":240,"elapsed":5,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"outputs":[],"source":["def translate(sentence):\n","    result, sentence = evaluate(sentence)\n","    print('Input : %s' % (sentence))\n","    print('predicted sentence :{}'.format(result))\n","    \n","    return result"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"7bph5zvYTlIF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660430038263,"user_tz":240,"elapsed":151,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}},"outputId":"ab1794c2-ef68-4d69-ddbe-23a2b0a7c7ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input : start_ ¿ vosotros tomar el almuerzo juntos ? _end\n","predicted sentence :retain avoided banker quite historian prayers impounded bookkeeping shooting miss biodegradable hotel \n"]}],"source":["sent_to_translate = \"¿Vosotros tomar el almuerzo juntos?\"\n","pred = translate(sent_to_translate)\n"]},{"cell_type":"code","source":["!pip3 uninstall googletrans\n","!pip3 install googletrans==3.1.0a0"],"metadata":{"id":"jmYd7Zz0FTWd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from googletrans import Translator\n","translator = Translator()\n","translation = translator.translate(sent_to_translate, dest='en')\n","print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAfNTRgX_rJg","executionInfo":{"status":"ok","timestamp":1660430045100,"user_tz":240,"elapsed":257,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}},"outputId":"280bb29f-0a1a-4935-8809-c536ec065ae5"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["¿Vosotros tomar el almuerzo juntos? (es) --> Do you guys have lunch together? (en)\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Neural Machine Translation/testing.py')"],"metadata":{"id":"5lHzS-l3WbtO","executionInfo":{"status":"ok","timestamp":1660430270981,"user_tz":240,"elapsed":111,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["!pip install rouge\n","!pip install sentence_transformers"],"metadata":{"id":"14XBepoQXLNG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from testing import Testing\n","from tqdm import tqdm\n","names = ['english', 'spanish', 'version_details']\n","test_data = pd.read_csv(data_path , delimiter='\\t', names=names)[96000:]\n","print(test_data.columns)\n","expected = test_data['spanish']\n","pred = list(test_data['english'])\n","temp = []\n","for  sentence in range(len(pred)):\n","  temp.append(pred)\n","\n","\n","metrics = Testing(pred, expected)\n","metrics.score()\n","\n","print(\"Precision: \",metrics.precision)\n","print(\"Recall Score: \",metrics.recall)\n","print(\"F1 Score: \",metrics.f1)\n","print(\"Bleu Score: \",metrics.bleu)"],"metadata":{"id":"1rCN6FXq7MI_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660430934974,"user_tz":240,"elapsed":113,"user":{"displayName":"Mrudula K","userId":"06577924550070583774"}},"outputId":"f6ae7170-66da-4da7-a4ec-72e4c0dd33dc"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision:  0.4585099​\n","Recall Score:  0.4666502​\n","F1 Score:  0.4774437\n","Bleu Score:  0.3732495​\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Seq2Seq_without_attention.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}